#
# Copyright 2011-2013, Dell
# Copyright 2013-2014, SUSE LINUX Products GmbH
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

en:
  nav:
    pacemaker: 'Pacemaker'
  api:
    pacemaker:
      ha_not_installed: 'HA add-on is not installed.'
      ha_not_configured: 'No Pacemaker cluster is configured.'
  barclamp:
    pacemaker:
      edit_attributes:
        haproxy_header: 'HAProxy'
        haproxy:
          ssl_info:
            'The hostname for each virtual IP of HAProxy is generated by
            prefixing the name of the network to "%{vhostname}". For instance,
            the hostname of the admin virtual IP will be "admin.%{vhostname}".
            If using SSL for services that will be served behind HAProxy, then
            the SSL certificates will have to be valid for the hostname of the
            virtual IP for each network being used (in general, admin and
            public), and for the public name if defined.'
          public_name: 'Public name for public virtual IP'
          public_name_hint:
            'The public name is the hostname that will be used instead of the
            generated public name for the public virtual IP of HAProxy (when
            registering public endpoints, for instance). Any name specified
            here should already exist in the upstream DNS zones.'
        gui_header: 'Pacemaker GUI'
        corosync_rings_header: 'Corosync Rings'
        corosync:
          password: 'Password for hacluster user in Hawk'
          transport: 'Transport for Communication'
          transports:
            udp: 'Multicast (UDP)'
            udpu: 'Unicast (UDPU)'
          require_clean_for_autostart_wrapper: 'Do not start corosync on boot after fencing'
          require_clean_for_autostart_values:
            auto: 'Automatic'
            v_true: 'True'
            v_false: 'False'
          require_clean_for_autostart_hint:
            'This setting can be used to avoid the STONITH deathmatch issue for
            two-nodes clusters, or a fencing loop. The corosync service will
            not start on boot on a node when that node was not properly shut
            down or rebooted; you will have to manually start it after having
            fixed the issue. "Automatic" means that this setting will be set to
            "true" for two-nodes cluster, and to "false" otherwise.'
          loading_text: 'Loading rings...'
          ring_header: 'Ring %{index}'
          add_header: 'Ring 2'
          add_button: 'Add Second Ring'
          rings:
            index:
              network: 'Network'
              mcast_addr: 'Multicast Address'
            network_placeholder: 'A network defined in the network barclamp (admin, storage, etc.)'
            mcast_placeholder: 'An address in the multicast range, such as 239.255.0.1; it must be unique accross Pacemaker proposals'
        pacemaker_header: 'Pacemaker Parameters'
        crm:
          no_quorum_policy: 'Policy when cluster does not have quorum'
          no_quorum_policy_hint_html: 'Refer to the <a href="http://clusterlabs.org/doc/en-US/Pacemaker/1.1-crmsh/html/Pacemaker_Explained/_available_cluster_options.html">pacemaker documentation</a> for a description of each value.'
        stonith_header: 'STONITH'
        stonith_modes:
          manual: 'Configured manually'
          ipmi_barclamp: 'Configured with IPMI data from IPMI barclamp'
          sbd: 'Configured with STONITH Block Devices (SBD)'
          shared: 'Configured with one shared resource for the whole cluster'
          per_node: 'Configured with one resource per node'
        stonith:
          mode: 'Configuration mode for STONITH'
          no_nodes: 'No nodes have been assigned a pacemaker role.'
          sbd:
            info_html: 'Manual configuration is required for SBD: before applying the proposal, you will have to ensure that the devices are available and initialized for SBD. You will also need to manually setup a watchdog if not all nodes use the same watchdog kernel module. Refer to the <a href="http://www.linux-ha.org/wiki/SBD_Fencing">Linux HA documentation</a> for details.'
            name: 'Node name'
            watchdog_module: 'Kernel module for watchdog'
            watchdog_module_hint: 'Leave the watchdog module attribute empty if the nodes need different watchdog modules.'
            devices: 'Block devices for node'
            devices_hint: 'Multiple devices can be specified in the comma-separated list. It is advised to use a stable path for devices (with /dev/disk/by-id/, for instance).'
          shared:
            agent: 'Fencing agent'
            params: 'Parameters for agent'
          per_node:
            agent: 'Fencing agent'
            name: 'Node name'
            params: 'Parameters for agent'
        notifications_header: 'Mail Notifications'
        notifications:
          smtp:
            enabled: 'Enable Mail Notifications'
            server: 'SMTP Server'
            server_hint: 'Note that the SMTP server needs to be reachable from the nodes.'
            prefix: 'Subject Prefix'
            from: 'Sender Address'
            to: 'Recipient Address'
      validation:
        missing_sbd_device: 'Missing SBD devices for node %{member}.'
        empty_sbd_device: 'Some SBD devices for node %{node_name} are empty.'
        missing_sbd_for_node: 'Missing SBD devices for node %{node_name}.'
        node_no_cluster_member: 'SBD devices present for node %{node_name}, while this node is not a member of the cluster.'
        same_number_of_devices: 'All nodes must share the same number of SBD devices (with possibly different paths).'
        missing_fencing_agent: 'Missing fencing agent for shared setup.'
        missing_fencing_agent_params: 'Missing fencing agent parameters for shared setup.'
        shared_params_no_hostlist: 'The hostlist for fencing agent parameters for shared setup must not included as it will be automatically computed.'
        missing_fencing_agent_per_node: 'Missing fencing agent for per-node setup.'
        node_missing_fencing_params: 'Missing fencing agent parameters for node %{member}'
        fencing_agent_no_cluster: 'Fencing agent parameters present for node %{node_name}, while this node is not a member of the cluster.'
        automatic_ipmi_setup: 'Automatic IPMI setup not available for node %{member}.'
        hypervisor_ip: 'Hypervisor IP \"%{hypervisor_ip}\" is invalid.'
        libvirt: 'Node  %{member} does not seem to be running in libvirt.'
        stonith_mode: 'Unknown STONITH mode: %{stonith_mode}.'
        hawk_server: 'Node %{name} has the hawk-server role but not the pacemaker-cluster-member role.'
        smtp_server: 'Invalid SMTP server for mail notifications.'
        sender_address: 'Invalid sender address for mail notifications.'
        recipient_address: 'Invalid recipient address for mail notifications.'
        no_new_drbd: 'DRBD is not allowed for new deployments since services can not be configured to use it anymore.'
        drbd: 'Setting up DRBD requires a cluster of two nodes.'
        ha_repo: 'The SLE HA repositories have not been setup.'
        transport_value: 'Invalid transport value: %{transport}.'
        ring_network_too_many: 'Too many rings specified. Only two rings are allowed.'
        ring_network_empty: 'A network must be specified for the %{ring_ordinal} corosync ring.'
        ring_network_notfound: 'Network "%{ring_network}" not found for the %{ring_ordinal} corosync ring.'
        ring_network_notunique: 'The network "%{ring_network}" has been specified more than once.'
        allocate_ip: 'Failed to allocate address for node "%{node}" on network "%{network}" (Error %{retcode}).'
        mcast_addr_empty_free: 'A multicast address for ring %{ring_index} is required. Multicast address %{free_addr} is available.'
        mcast_addr_used_free: 'The specified multicast address %{used_addr} for ring %{ring_index} is in use but %{free_addr} is available.'
        mcast_addr_used_none_avail: 'All multicast addresses are in use, including %{used_addr}.'
        mcast_addr_none_avail: 'All multicast addresses are in use.'
        quorum_policy: 'Invalid no-quorum-policy value: %{no_quorum_policy}.'
        platform: 'All nodes in proposal must have the same platform.'
        pacemaker_proposal: 'Nodes cannot be part of multiple Pacemaker proposals, but %{other_member} is already part of proposal \"%{p_name}\".'
        cluster_size_even:
          'Clusters must have an odd number of nodes to ensure quorum during
          partitioning. 2-node clusters are allowed as a special exception.'
